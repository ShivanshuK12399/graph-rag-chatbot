Graph RAG Chatbot with Auto-Updating Memory


ğŸ“Œ Overview
This project implements a Graph-based Retrieval-Augmented Generation (RAG) chatbot that maintains structured memory using a knowledge graph.
When a user provides new information, the system extracts structured facts and stores them in a graph database. When the user asks a question, the system retrieves relevant graph context and uses an LLM to generate a response strictly based on stored memory.
The system supports multi-user memory separation.


ğŸ—ï¸ Architecture
User Input
    â†“
Information Extraction (Rule-based / spaCy)
    â†“
Graph Update (NetworkX)
    â†“
Graph Retrieval
    â†“
LLM Formatting (Gemini/Groq API)
    â†“
Final Response


ğŸ› ï¸ Tech Stack
Python
Streamlit â€“ Web interface
NetworkX â€“ Knowledge graph
spaCy / Rule-based extraction â€“ Information extraction
Gemini / Groq API â€“ LLM response formatting
Matplotlib / Pyvis â€“ Graph visualization


ğŸ§  How It Works

1ï¸âƒ£ Memory Addition

When the user provides structured input such as:
â€œI work at Brainzymâ€
â€œI like Unityâ€
â€œI study AIâ€

The system extracts triples in the format: (User, RELATION, Entity)

Example:
(Shivanshu, WORKS_AT, Brainzym)
(Shivanshu, LIKES, Unity)

These are stored as nodes and edges inside a NetworkX multi-directed graph.

2ï¸âƒ£ Memory Retrieval

When the user asks:
â€œWhere do I work?â€
â€œWhat do I like?â€

The system:
Detects intent
Maps question to relation
Queries graph
Retrieves matching triples
Sends them as context to the LLM

If no memory is found, the system responds: I don't know.
The LLM is strictly instructed to answer only using retrieved graph context.


ğŸ‘¥ Multi-User Support

Each user has isolated memory based on a unique user_id.
Graph queries are scoped per user to prevent cross-memory leakage.


ğŸ“Š 10 Memory Inputs

Use this sequence:
I work at Google.
I live in Delhi.
I study at JSS Noida.
I study mathematics.
I like football.
I like machine learning.
I work at Microsoft.
I live in India.
I study physics.
I like coding.

After entering, click Show Graph to demonstrate graph visualization.


â“ 5 Query Demonstrations

Where do I work?
Where do I live?
Where do I study?
What do I study?
What do I like?


ğŸ“ˆ Graph Visualization

The application includes a live visualization of the memory graph showing:

User nodes
Entity nodes
Relationship edges
![Graph visualization](images/graph.png)
This enables visual inspection of stored knowledge.


ğŸš€ How to Run Locally

1. Clone Repository
git clone https://github.com/ShivanshuK12399/graph-rag-chatbot
cd Graph-RAG-Chatbot

2. Install Dependencies
pip install -r requirements.txt

3. Run Application
py -m streamlit run app.py


ğŸ“ Project Structure
Graph-RAG-Chatbot/
â”‚
â”œâ”€â”€ app.py
â”œâ”€â”€ graph_memory.py
â”œâ”€â”€ extraction.py
â”œâ”€â”€ llm_service.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ reflection.md


âš ï¸ Known Limitations

1ï¸âƒ£ Limited Verb Coverage (Hard-Coded Ontology)

Your system only understands: work, live, study, like
Anything outside that is ignored.

Example failures:
I built a game.
I prefer Python.
I hate maths.
I moved to Delhi.
I completed B.Tech.

These wonâ€™t be stored.
Because you require explicit verb â†’ relation mapping. This is a structural limitation of controlled ontology design.

2ï¸âƒ£ No Memory Update / Conflict Resolution

If user says:
I work at Google.
I work at Microsoft.
I do not work at Google.

My system:
Stores Google
Stores Microsoft
Ignores negation
Never deletes old fact

There is no temporal awareness, no contradiction handling, no update logic.
Memory only grows. It never corrects itself.

3ï¸âƒ£ No Temporal Context

You cannot represent:
I worked at Google in 2022.
I used to live in Mumbai.
I will study in Germany next year.

All facts are treated as permanent truth, graph memory lacks time dimension.

4ï¸âƒ£ Fragile NLP Scope

spaCy extraction handles: Simple first-person declarative sentences

It does NOT handle:
Passive voice - â€œGoogle employs me.â€
Indirect phrasing - â€œCurrently employed by Google.â€
Complex clauses - â€œAlthough I studied maths, I now study physics.â€
Pronoun resolution - â€œI joined Microsoft. Itâ€™s great.â€

No multi-sentence reasoning.

5ï¸âƒ£ No Semantic Generalization

If user says: I enjoy football.
Your system does not map "enjoy" â†’ LIKES.

No synonym handling.
No embedding-based similarity.

Everything depends on exact verb lemma match.

7ï¸âƒ£ No Persistence (If Not Implemented)

If graph resets on restart, memory is volatile, Not real-world ready.

âš ï¸ NOTE - In llm_service : client = Groq(api_key=os.environ.get("GROQ_API_KEY"))
I intentionally didn't mentioned my API key due to security reasons